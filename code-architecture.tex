\section{Code Design}
In the following section we go over the design and rationale of our choices
for the development of the code.

\subsection{Overall Class Design Considerations}
\subsubsection{Field Registration}
Form our past experience, we have found one of the challenging problems in maintaining codes
is that of adding new fields. There are many reasons why to add new fields, for example,
an implementation of new physics (mhd, radiation, chemistry etc.) or adding a passive scalar
to track some portion of fluid or modification of existing algorithm that needs an auxiliary
field that has not been stored. In any case, the addition of a new field can be challenging
if the computation has been hard coded or the data structures, for example C structs, do not
allow the addition of new fields. For this reason, we early on adopted a data structure
that allows registration of fields. In this manner fields can be added at any later point.

For these considerations we will see a common thread with most of our classes. Most of our
classes will have some form of registration or addition of fields. For registration, the
class usually inspects the particle data structure and creates the fields necessary to
during the simulation. In the case of addition, the class will search the particles fields
and if the fields are not present the class will add them.

\subsubsection{Class Registration}
Another source for future problems is when an algorithm depends on another. For example
our gravity tree solver depends on our load balance implementation. If these algorithms
where designed concurrently then though would be taken on how they should interact
with one another. However, it is very common that new implementations are needed after 
due to the progression of new algorithms. In these situations common options are to re-factor
the algorithms or even rewrite the algorithm itself.

In our case we decided to write our classes as stand alone computations

\subsection{Particle Data Structures}
\subsubsection{Carray}
In choosing the underlying data structure several considerations where taken. First the
data had to be accessible in python and in C. Second the data structure had to
accommodate several data types. For this reason we choose a data structure that mimics
numpy arrays, in the sense that raw data is allocated in C and interface exist that
manipulates the data in either C or python. With this approach a decision had to be
made in the form of the raw data. Two choices where considered, either the data would
be held in structs or arrays. The benefit of structs would allow subfields of the data
be compact and allow easy implementations of passing and receiving data from other
processors in parallel runs. Further numpy has an interface, that treats
arrays of structs as record numpy arrays. However, this form was abandoned early on
as the sub-fields would have to be hard coded and would not allow the creation of
dynamic fields at run time. With this consideration, the raw data was chosen to be
c arrays. 

The exact implementation was taken from pysph code. The class is called Carray and
can be initialized in Python or Cython. The interface closely resembles the list
class of c++, in allowing indexing and memory management. Further, Carrays can return
a numpy array, allowing the user to use all numpy functional (i.e. slicing and fancy indexing). 
Below is a simple example using a Carray.
\begin{lstlisting}
import phd

x = phd.DoubleArray(10)
for i range(len(x)):
	x[i] = i**2
    
x.append(3.21)
x.resize(5)

xnp = x.get_npy_array()
xnp[:] = np.arange(x.length)
\end{lstlisting}
In this example a Carray is created with 10 doubles, then assigned values by indexing. Notice
that the length of the Carray can be found either by the len function or the length
attribute. The Carray then has a value appended to it followed by resizing the Carray to a length
of 5. Finally, the get npy array is called returning a numpy array which allows the use of slicing.

\subsubsection{CarrayContainer}
The use of Carrays allow to easily manipulate arrays of certain type of data. However, there are
many circumstances for the need of a collection of Carrays. For example the x, y, and z position
of a particle or the center of mass and moments of a node in the gravitational tree. Therefore,
another data structure has been implemented to facilitate the use of collection of Carrays. The data
structure is called a CarrayContainer and like the Carray it has many methods to manipulate the
underlying data. The CarrayContainer in some aspects mimics a python dictionary in the sense
that each carray can be retrieved by a string key.
\begin{lstlisting}
import phd
import numpy as np

carrys = {"x": "double", "y", "double"}

ca_con = phd.CarrayContainer(10, carrays)
size = ca_con.get_carray_size()
ca_con["x"][:] = np.random.rand(size)
ca_con["y"][:] = np.random.rand(size)

ca_con2 = phd.CarrayContainer(5, carrays)
size = ca_con.get_carray_size()
ca_con["x"][:] = np.random.rand(size)
ca_con["y"][:] = np.random.rand(size)

ca_con.append(ca_con2)
ca_con.remove(np.array([1, 3, 9])
\end{lstlisting}
Most of the routines of Carrays have been extended to CarrayConatiner to operate on
all Carrays in the Container. Further the container has routines to subset, remove, paste
and add values to certain elements.

\subsection{Simulation Class}
The \lstinline{Simulation} class is the main driver for advancing the solution in time
and coordinating outputs to disk and terminal. The two most important methods of this
class are listed below
\begin{itemize}
    \item \lstinline{solve()}: advance \lstinline{IntegrateBase} to its final state while
        outputting all necessary information. 
    \item \lstinline{compute_time_step()}: aggregate all time steps and enforce the smallest.
\end{itemize}
From its inception, the class was designed to be independent of the solvers. This was 
accomplished by distinguishing state computation and state advancing methods. For example,
\lstinline{IntegrateBase} can only perform a computation at a given temporal state 
(see Section~\ref{sec.integrator} for details) while \lstinline{Simulation} can
dictate when and the number of computations. Thus, \lstinline{Simulation} controls the
time advancement independently of the equations being solved. As of writing three integrators
exist, however, adding a new integrator is relatively straightforward.

During the course of a simulation the class is responsible to schedule outputs and
determined if the simulation has completed. Simulation outputs and termination are 
designated by the \lstinline{SimulationOutputerBase} and \lstinline{SimulationFinisherBase} 
classes respectively (see Section~\ref{sec.outputters} for details). At the end of every time
step the class calls \lstinline{compute_time_step()} to modify the current time step and
output any necessary data by cycling through all outputters. Likewise, at the beginning of
the time step the class cycles through all \lstinline{SimulationFinisherBase} classes 
search for a termination signal.

Lastly, the simulation class also controls logging information (see Section~\ref{sec.logging}
for details). 
Log information is currently printed to the terminal and saved to a log file. The simulation class 
allows the ability to pick how much information should be printed and saved. In parallel runs, the 
root processor takes responsibility for writing to the log file and displaying to terminal.

\subsubsection{Serialization of classes and parameters}

\subsection{Mesh Class}
\subsubsection{Tessellation}
\subsubsection{Grid Motion}
\subsubsection{Flux Update}

\subsection{Integrator Class}
\label{sec.integrator}

\subsection{Hydro Class}
\subsubsection{Reconstruction}
\subsubsection{Riemann Solver}

\subsection{General Source Terms}
The inclusion of source terms has been implemented through a general source
\lstinline{SourceTermBase} with methods listed below:
\begin{itemize}
    \item \lstinline{apply_primitve()}: modify primitive variables.
    \item \lstinline{apply_conservative()}: modify consevative variables.
    \item \lstinline{apply_flux()}: modify flux terms.
    \item \lstinline{compute_source()}: calculate soure components.
    \item \lstinline{compute_time_step()}: calculate time step from source term.
\end{itemize}
This formulation was chosen after some considerable experimentation. One of the
earlier attempts was a registration process. In this scenario a source term
would link any computation to class method. This information was stored
in a dictionary inside \lstinline{Simulation} and at runtime each class method
was over written using Pythons decorator shcheme. Although, this scheme makes
use of more advnace programming methods we found that this implementation was
not easy to discern. Moreover we found that this method left to much ambiguity
to the source terms, allowing . Instead we
found this current implementation to be more understanble and easier to
generalize.

The api listed above are the mandatory methods to be defined for any source
term. In general, we write an interface for each given source term. In this
way if the integrator changes only the api has to be updated leaving
the core of the source term unaltered. This also allows to easily implement
third party libraries as source terms, chemsitry or radiation for example.
Once the methods have been defined the class is registered to 
\lstinline{Simulation} class and will be invoked at the appropriate parts
during the computation.

\subsubsection{Gravity}
For a more concrete example of how to include a source term we highlight the
pieces used to include self gravity. Our self gravity is a tree based implemetation
named \lstinline{GravityTree}. Its main routine is \lstinline{walk()} which is the
calculation of gravitational accelerations from the current position of the particles.
To include this as a source term we created a new class called \lstinline{SelfGravity}
which inherits \lstinline{SourceTermBase}. As disscussed in section, gravity alters
the momentum and primitive values.
\begin{lstlisting}
...
cdef class SelfGravity(MUSCLHancockSourceTerm):
    ...
    cpdef apply_primitive(self, object integrator):
        # loop over each face in the mesh 
        for m in range(integrator.mesh.faces.get_carray_size()):
            ....
            # add gravity to velocity
            for k in range(dim):
                vl[k][m] += 0.5*dt*a[k][i]
                vr[k][m] += 0.5*dt*a[k][j]

        # add gravity acceleration from particle
        for i in range(integrator.particles.get_carray_size()):
            ...
                for k in range(dim):
                    # update momentum
                    e.data[i] += 0.5*dt*mv[k][i]*a[k][i]

                    # update energy 
                    mv[k][i] += 0.5*dt*mass.data[i]*a[k][i]

    cpdef apply_conservative(self, object integrator):
        ...
        # add gravity acceleration from particle
        for i in range(integrator.particles.get_carray_size()):
            ...
                for k in range(dim):
                    # update momentum
                    mv[k][i] += 0.5*dt*mass.data[i]*a[k][i]

                    # update energy 
                    e.data[i] += 0.5*dt*mv[k][i]*a[k][i]
\end{lstlisting}

\subsection{Readers/Writers}
\subsubsection{HDF5}

\subsection{Outputters and Finishers}
\label{sec.outputters}
The code has been desinged to handel arbritary signals for outputing data
and completion of the simulation. 

\subsubsection{Design API}
\subsubsection{Examples}
In this section we show, some what trivial but highlights the main points, an example of
how to create an outputter and finisher. For our example, we use the sedov problem from 
section cite. We are interested to output all time steps once the shock has reached
a density $\rho=2$ and remains less than $\rho=3$. Of course in this situation one may
use the analytical solution to extraplote when such values would occur. However that
assumes the shock track exactly. In our scenario we let the simulation do the work
for us.

First we begin by defining an outputter with the objective to start outputing
all data once the density value of $\rho=2$ has been reached (see code excerpt). This
is accomplished by inherting \lstinline{SimulationOutputerBase} and modifying
\lstinline{check_for_output} and \lstinline{modify_timestep}.


\begin{lstlisting}
...
class OutputSedovDensity(SimulationOutputterBase):
    def __init__(self, density_min, base_name="density_output",
                 counter=0, pad=4, **kwargs):
        super(OutputSedovDensity, self).__init__(base_name, counter, pad, **kwargs)
        self.density_min = density_min 

    def check_for_output(self, simulation):
        """Return True to signal the simulation has reached
        sedov interval to ouput data."""
        integrator = simulation.integrator
        state = simulation._state == SimulationTAGS.MAIN_LOOP
        output_sedov = simulation.integrator.particles["density"].max() > self.density_min:

        if state and output_sedov:
            return True
        return False

    def modify_timestep(self, simulation):
        """Return consistent time step."""
        # not modifying
        return simulation.integrator.dt

\end{lstlisting}

\begin{lstlisting}
...
class SedovDensityFinisher(SimulationFinisherBase):
    ...
    def __init__(self, density_max):
        self.density_max = density_max

    def finished(self, simulation):
        """Return True to signal the simulation is finished
        if reached max iteration number.
        """
        if simulation.integrator.particles["density"].max() >= self.density_max:
            return True
        else:
            return False

\end{lstlisting}

\subsection{Load Balance}

\subsection{Equation of State}

\subsection{Domain Manager}
\subsubsection{Internal Boundary Particle Sharing}
\subsubsection{Particle Motion}
\subsubsection{Boundary Condition}

\subsection{Logging}
\label{sec.logging}
\begin{itemize}
	\item debug: detailed information or diagnosing.
    \item info: working as expected.
    \item success: a successful completion. 
    \item warning: unexpected result that may lead to future problem.
\end{itemize}

\subsection{Units}

\subsection{Profiling}
